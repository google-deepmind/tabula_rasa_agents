{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ESPnYjb6CJH-"
      },
      "outputs": [],
      "source": [
        "#@title Imports.\n",
        "import io\n",
        "import math\n",
        "import requests\n",
        "from typing import List, Optional, Sequence, Tuple\n",
        "import warnings\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy.stats\n",
        "\n",
        "warnings.simplefilter('ignore', category=RuntimeWarning)\n",
        "from IPython.display import clear_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jWFQngzZsjVx"
      },
      "outputs": [],
      "source": [
        "CATCH = 3e7\n",
        "NUMBER_OF_TIMEBINS = int(1.5e9/CATCH)\n",
        "LEGEND = ['8:0|8:0', '8:0|7:1', '8:0|6:2', '8:0|5:3', '8:0|4:4']\n",
        "YLIM = (0, 1)\n",
        "DOWNSAMPLE = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xeFHcFlErfZq"
      },
      "outputs": [],
      "source": [
        "#@title Plot metric function\n",
        "def plot_metric_style(\n",
        "    *,\n",
        "    dataframes: Sequence[pd.DataFrame],\n",
        "    eval_name: str,\n",
        "    first_choice: str,\n",
        "    second_choice: str,\n",
        "    number_of_timebins: int,\n",
        "    number_of_agents_to_eval: int,\n",
        "    titles: List[str],\n",
        ") -\u003e Tuple[\n",
        "    np.ndarray,\n",
        "    List[float],\n",
        "    List[float],\n",
        "    Tuple[List[float], ...],\n",
        "    List[Tuple[np.ndarray, np.ndarray]]]:\n",
        "  \"\"\"Plot the bias evaluation for each run.\n",
        "\n",
        "  Args:\n",
        "    dataframes: Dataframes that constitute one experiment (one run per plot).\n",
        "    eval_name: Name of evaluation that was run.\n",
        "    first_choice: Identity of the first target in the dual choice eval.\n",
        "    second_choice: Identity of the second target in the dual choice eval.\n",
        "    number_of_timebins: Number of bins for the x axis.\n",
        "    number_of_agents_to_eval: Number of agents to evaluate.\n",
        "    titles: Titles of runs.\n",
        "\n",
        "  Returns:\n",
        "    (Nested) tuple of aggregated statistics about the experiment.\n",
        "\n",
        "  \"\"\"\n",
        "  cols = len(dataframes)\n",
        "  plt.subplots(1, cols, figsize=(cols * 3.5, 3), facecolor='white')\n",
        "  y_differences = []\n",
        "  y_errors = []\n",
        "  y_reds = []\n",
        "  y_blues = []\n",
        "  mean_red_errors = []\n",
        "  mean_blue_errors = []\n",
        "  raw_ys = []\n",
        "  for c, df in enumerate(dataframes):\n",
        "\n",
        "    plt.subplot(1, cols, c + 1)\n",
        "    x_red, y_red, y_red_error, red_players = get_series(\n",
        "        df=df,\n",
        "        player_color='red',\n",
        "        eval_name=eval_name,\n",
        "        number_of_agents_to_eval=number_of_agents_to_eval,\n",
        "        number_of_timebins=number_of_timebins,\n",
        "    )\n",
        "    plt.plot(x_red, y_red, 'or')\n",
        "    plt.plot(x_red, y_red, '-', color='red')\n",
        "    plt.fill_between(\n",
        "        x_red, y_red - y_red_error, y_red + y_red_error, color='red', alpha=0.2\n",
        "    )\n",
        "\n",
        "    x_blue, y_blue, y_blue_error, blue_players = get_series(\n",
        "        df=df,\n",
        "        player_color='blue',\n",
        "        eval_name=eval_name,\n",
        "        number_of_agents_to_eval=number_of_agents_to_eval,\n",
        "        number_of_timebins=number_of_timebins,\n",
        "    )\n",
        "    plt.plot(x_blue, y_blue, 'ob')\n",
        "    plt.plot(x_blue, y_blue, '-', color='blue')\n",
        "    plt.fill_between(\n",
        "        x_blue,\n",
        "        y_blue - y_blue_error,\n",
        "        y_blue + y_blue_error,\n",
        "        color='blue',\n",
        "        alpha=0.2,\n",
        "    )\n",
        "\n",
        "    plt.hlines(0.5, 0, np.max(x_red), 'black')\n",
        "    plt.ylim(0, 1)\n",
        "    plt.ylabel(f'{second_choice} bias to {first_choice} bias', labelpad=-2)\n",
        "    plt.xlim(0, 1.5e9)\n",
        "    plt.xticks([0, 0.5e9, 1e9, 1.5e9], ['0', '0.5e9', '1e9', '1.5e9'])\n",
        "    plt.xlabel('Training steps')\n",
        "    plt.title(titles[c])\n",
        "    assert len(y_blue) == len(y_red)\n",
        "    c = c + 1\n",
        "\n",
        "    y_differences.append(y_red - y_blue)\n",
        "    y_errors.append((y_red_error + y_blue_error) / 2)\n",
        "    y_reds.append(np.mean(y_red))\n",
        "    y_blues.append(np.mean(y_blue))\n",
        "    mean_red_errors.append(np.mean(y_red_error))\n",
        "    mean_blue_errors.append(np.mean(y_blue_error))\n",
        "    raw_ys.append((red_players, blue_players))\n",
        "\n",
        "  discrimination_information = (\n",
        "      y_reds,\n",
        "      y_blues,\n",
        "      mean_red_errors,\n",
        "      mean_blue_errors,\n",
        "  )\n",
        "\n",
        "  plt.savefig('evaluation_metrics.svg', dpi=100)\n",
        "  return x_red, y_differences, y_errors, discrimination_information, raw_ys\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "adLHzQ-tLjUD"
      },
      "outputs": [],
      "source": [
        "#@title Load dataframes function\n",
        "def load_dataframes(*,\n",
        "                    file_label: str,\n",
        "                    number_of_files: int,\n",
        "                    downsample: bool) -\u003e List[pd.DataFrame]:\n",
        "  \"\"\"Load dataframes from cloud bucket.\n",
        "\n",
        "  Args:\n",
        "    file_label: Label of the filenames.\n",
        "    number_of_files: How many files are in the experiment (one per run).\n",
        "    downsample: Whether to downsample or not.\n",
        "\n",
        "  Returns:\n",
        "    List of dataframes.\n",
        "\n",
        "  \"\"\"\n",
        "  df_list_output = []\n",
        "  for file_number in range(number_of_files):\n",
        "    file_location = (\n",
        "        f'https://storage.googleapis.com/tabula_rasa_agents/{file_label}_{file_number}.csv'\n",
        "    )\n",
        "    response = requests.get(file_location)\n",
        "    with io.BytesIO(response.content) as f:\n",
        "      df = pd.read_csv(f, na_values=['NaN']).fillna(0)\n",
        "      if downsample:\n",
        "        # The df size is already curtailed to 100k, for ease of use it is\n",
        "        # reduced even further here.\n",
        "        df = df.sample(frac=0.5)\n",
        "      df_list_output.append(df)\n",
        "  clear_output()\n",
        "  return df_list_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZUiqxyT_rnZB"
      },
      "outputs": [],
      "source": [
        "#@title Get data series function\n",
        "def get_series(\n",
        "    *,\n",
        "    df: pd.DataFrame,\n",
        "    player_color: str,\n",
        "    eval_name: str,\n",
        "    number_of_agents_to_eval: int,\n",
        "    number_of_timebins: int = NUMBER_OF_TIMEBINS,\n",
        ") -\u003e Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
        "  \"\"\"Obtain data of one eval run.\n",
        "\n",
        "  Args:\n",
        "    df: Dataframe of one run.\n",
        "    player_color: Color of agent that is evaluated.\n",
        "    eval_name: Name of the evaluation.\n",
        "    number_of_agents_to_eval:  Number of agents to evaluate.\n",
        "    number_of_timebins: Number of timebins for the x axis.\n",
        "\n",
        "  Returns:\n",
        "    Tuple of arrays containing run eval data.\n",
        "  \"\"\"\n",
        "  reference_x = None\n",
        "  y_raw = np.zeros((number_of_agents_to_eval, number_of_timebins))\n",
        "  # The first few agents are the dummies we use to eval.\n",
        "  for i, p in enumerate(range(8 - number_of_agents_to_eval, 8)):\n",
        "    # Target 2 is red 3 is blue\n",
        "    first_target_x, first_target_y = get_player_interactions(\n",
        "        df=df,\n",
        "        player_color=player_color,\n",
        "        player_number=p,\n",
        "        target_number=2,\n",
        "        eval_name=eval_name,\n",
        "    )\n",
        "    second_target_x, second_target_y = get_player_interactions(\n",
        "        df=df,\n",
        "        player_color=player_color,\n",
        "        player_number=p,\n",
        "        target_number=3,\n",
        "        eval_name=eval_name,\n",
        "    )\n",
        "    x, y, reference_x = interaction_fraction_within_player(\n",
        "        first_target_x=first_target_x,\n",
        "        first_target_y=first_target_y,\n",
        "        second_target_x=second_target_x,\n",
        "        second_target_y=second_target_y,\n",
        "        reference_x=reference_x,\n",
        "    )\n",
        "    x = x[0:number_of_timebins]\n",
        "    y = y[0:number_of_timebins]\n",
        "    y_raw[i, :] = y\n",
        "  y_raw = y_raw.T\n",
        "  y_error = (np.std(y_raw, axis=1) / math.sqrt(y_raw.shape[1])) * 1.96\n",
        "  y_mean = np.mean(y_raw, axis=1)\n",
        "\n",
        "  assert x.ndim == 1\n",
        "  assert y_mean.ndim == 1\n",
        "  assert y_error.ndim == 1\n",
        "  return x, y_mean, y_error, y_raw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LEcvSOBKrucS"
      },
      "outputs": [],
      "source": [
        "#@title Get player interaction function\n",
        "def get_player_interactions(\n",
        "    *,\n",
        "    df: pd.DataFrame,\n",
        "    player_color: str,\n",
        "    player_number: int,\n",
        "    target_number: int,\n",
        "    eval_name: str,\n",
        ") -\u003e Tuple[np.ndarray, np.ndarray]:\n",
        "  \"\"\"Extract interactions frome evaluation dataframe.\n",
        "\n",
        "  Args:\n",
        "    df: Dataframe with evaluation data.\n",
        "    player_color: Color of the agent to be evaluated, blue or red for\n",
        "    our purposes.\n",
        "    player_number: Number of the agent to be evaluated.\n",
        "    target_number: Number of the target agent.\n",
        "    eval_name: Name of the evaluation.\n",
        "\n",
        "  Returns:\n",
        "    Tuple of numpy arrays with the x (learner steps) and y values\n",
        "    of the interactions.\n",
        "  \"\"\"\n",
        "  leaner_frames = df[\n",
        "      f'{player_color}_{player_number}_behavior_{eval_name}:num_learner_frames'\n",
        "  ].to_numpy()\n",
        "  interaction_values = df[\n",
        "      f'{player_color}_{player_number}_behavior_{eval_name}:interaction_player_{target_number}'\n",
        "  ].to_numpy()\n",
        "  x = leaner_frames[interaction_values != np.array(None)]\n",
        "  y = interaction_values[interaction_values != np.array(None)]\n",
        "  assert x.shape[0] == y.shape[0]\n",
        "  assert x.ndim == 1\n",
        "  assert y.ndim == 1\n",
        "  return x, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "neGvBTk2r1rA"
      },
      "outputs": [],
      "source": [
        "#@title Interaction fraction within player function\n",
        "def interaction_fraction_within_player(\n",
        "    *,\n",
        "    first_target_x: np.ndarray,\n",
        "    first_target_y: np.ndarray,\n",
        "    second_target_x: np.ndarray,\n",
        "    second_target_y: np.ndarray,\n",
        "    reference_x: Optional[np.ndarray] = None,\n",
        ") -\u003e Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
        "  \"\"\"Get interaction_fractions of which target agent the evaluated agent interacts with.\n",
        "\n",
        "  In order to get the interaction_fraction of who the agent tends to interact\n",
        "  with we first\n",
        "  need to bin the data into chunks of the x axis (learner steps).\n",
        "\n",
        "  Args:\n",
        "    first_target_x: Agent learner steps of the first target agent eval.\n",
        "    first_target_y: Interactions with the first target agent.\n",
        "    second_target_x: Agent learner steps of the second target agent eval.\n",
        "    second_target_y: Interactions with the second target agent.\n",
        "    reference_x: Reference x axis values for the interactions. If None it will\n",
        "    be created.\n",
        "\n",
        "  Returns:\n",
        "    Tuple of numpy arrays with the x (learner steps) and y values\n",
        "    of the interactions (interaction_fraction between players).\n",
        "  \"\"\"\n",
        "  new_x = []\n",
        "  new_y = []\n",
        "  if reference_x is None:\n",
        "    reference_x = np.unique(np.round(first_target_x / CATCH))\n",
        "  for x_bin in reference_x:\n",
        "    new_x.append(x_bin * CATCH)\n",
        "    first_target_x_indices = np.where(np.round(first_target_x / CATCH) == x_bin)\n",
        "    first_target_y_vals = np.sum(first_target_y[first_target_x_indices])\n",
        "    second_target_x_indices = np.where(\n",
        "        np.round(second_target_x / CATCH) == x_bin\n",
        "    )\n",
        "    second_target_y_vals = np.sum(second_target_y[second_target_x_indices])\n",
        "\n",
        "    if (first_target_y_vals + second_target_y_vals) == 0:\n",
        "      interaction_fraction = 0.5\n",
        "    else:\n",
        "      interaction_fraction = float(\n",
        "          first_target_y_vals / (first_target_y_vals + second_target_y_vals)\n",
        "      )\n",
        "    new_y.append(interaction_fraction)\n",
        "  new_x = np.array(new_x)\n",
        "  new_y = np.squeeze(np.array(new_y))\n",
        "  assert new_x.shape == new_y.shape\n",
        "  assert new_x.ndim == 1\n",
        "  assert new_y.ndim == 1\n",
        "  assert reference_x.ndim == 1\n",
        "  return new_x, new_y, reference_x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IYyVHy9qaoYy"
      },
      "outputs": [],
      "source": [
        "#@title Overview plot function\n",
        "def overview_plot(\n",
        "    *,\n",
        "    x: np.ndarray,\n",
        "    y_differences: List[float],\n",
        "    y_errors: List[float],\n",
        "    legend_strings: str,\n",
        "    ylims: Tuple[float],\n",
        "    smooth_size: int = 5,\n",
        ") -\u003e List[float]:\n",
        "  \"\"\"Plot overviews of the group bias.\n",
        "\n",
        "  Args:\n",
        "    x: Values for X axis.\n",
        "    y_differences: Differences in the approach behavior for y axis.\n",
        "    y_errors: Error for the y axis.\n",
        "    legend_strings: Content for legend (one string per run).\n",
        "    ylims: Y axis limits.\n",
        "    smooth_size: How much to smooth the data for plotting.\n",
        "\n",
        "  Returns:\n",
        "    List of group biases (one per run).\n",
        "  \"\"\"\n",
        "  size = (5, 3)\n",
        "  setting_colors = [\n",
        "      '#6b6b73',\n",
        "      '#f58231',\n",
        "      '#dcbeff',\n",
        "      '#800000',\n",
        "      '#ffe119',\n",
        "      '#000075',\n",
        "      '#a9a9a9',\n",
        "      '#000000',\n",
        "  ]\n",
        "  bias_means = []\n",
        "  for i in range(len(y_differences)):\n",
        "    bias_means.append(np.mean(y_differences[i]))\n",
        "\n",
        "  plt.figure(facecolor='white', figsize=size)\n",
        "  plt.bar(range(len(y_differences)), np.array(bias_means), color=setting_colors)\n",
        "  plt.ylim(ylims)\n",
        "  plt.xticks(range(len(y_differences)), legend_strings)\n",
        "  plt.xlabel('Setting')\n",
        "  plt.ylabel('Mean of group bias over time')\n",
        "\n",
        "  plt.savefig('overview_bars.svg', dpi=200)\n",
        "\n",
        "  plt.figure(figsize=size)\n",
        "  for i in range(len(y_differences)):\n",
        "    y = smooth(y_differences[i], smooth_size=smooth_size)\n",
        "    plt.plot(x, y, c=setting_colors[i])\n",
        "    plt.fill_between(\n",
        "        x,\n",
        "        y - y_errors[i],\n",
        "        y + y_errors[i],\n",
        "        alpha=0.1,\n",
        "        label='_nolegend_',\n",
        "        color=setting_colors[i],\n",
        "    )\n",
        "\n",
        "  plt.hlines(0, 0, max(x), 'black')\n",
        "  plt.ylabel('In group bias')\n",
        "  plt.xlabel('Training steps')\n",
        "  plt.xticks([0, max(x)], [0, '1.5e9'])\n",
        "  plt.xticks(\n",
        "      [0, max(x) / 3, (max(x) / 3) * 2, max(x)], ['0', '0.5e9', '1e9', '1.5e9']\n",
        "  )\n",
        "\n",
        "  plt.ylim(-0.3, 1.1)\n",
        "  plt.savefig('overview.svg', dpi=200)\n",
        "  plt.show()\n",
        "\n",
        "  return bias_means"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vBvtNfzSyOH2"
      },
      "outputs": [],
      "source": [
        "#@title Individuation analyses function\n",
        "def individuation_analyses(\n",
        "    *,\n",
        "    freeze_levels: List[int],\n",
        "    red_individuation: Tuple[List[float], ...],\n",
        "    blue_individuation: Tuple[List[float], ...],\n",
        "    bias: List[np.ndarray],\n",
        "    label: str,\n",
        ") -\u003e Tuple[np.ndarray]:\n",
        "  \"\"\"Plot and analyse the individuation experiment.\n",
        "\n",
        "  Args:\n",
        "    freeze_levels: How negative the interaction is with the least desirable\n",
        "    agent (one value per run).\n",
        "    red_individuation: Individuation evaluation results of red agents.\n",
        "    blue_individuation: Individuation evaluation results of blue agents.\n",
        "    bias: Group bias evaluation results.\n",
        "    label: Label of experiment.\n",
        "\n",
        "  Returns:\n",
        "    Tuple containing the difference of individuation and group bias.\n",
        "  \"\"\"\n",
        "  size = (3, 2)\n",
        "  freeze_levels_str = [str(x) for x in freeze_levels]\n",
        "  number_of_runs = len(freeze_levels_str)\n",
        "  assert len(red_individuation[1]) == len(blue_individuation[1])\n",
        "  assert len(red_individuation[1]) == number_of_runs\n",
        "  assert len(blue_individuation[1]) == len(bias)\n",
        "  avoidance_of_less_rewarding_agent_ingroup_y = np.array([\n",
        "      1 - (red_individuation[0][x] + blue_individuation[1][x] / 2)\n",
        "      for x in range(number_of_runs)\n",
        "  ])\n",
        "  avoidance_of_less_rewarding_agent_outgroup_y = np.array([\n",
        "      1 - (red_individuation[1][x] + blue_individuation[0][x] / 2)\n",
        "      for x in range(number_of_runs)\n",
        "  ])\n",
        "  avoidance_of_less_rewarding_agent_ingroup_error = np.array([\n",
        "      (red_individuation[2][x] + blue_individuation[3][x] / 2)\n",
        "      for x in range(number_of_runs)\n",
        "  ])\n",
        "  avoidance_of_less_rewarding_agent_outgroup_error = np.array([\n",
        "      (red_individuation[3][x] + blue_individuation[2][x] / 2)\n",
        "      for x in range(number_of_runs)\n",
        "  ])\n",
        "\n",
        "  plt.figure(facecolor='white', figsize=size)\n",
        "  plt.plot(\n",
        "      freeze_levels, avoidance_of_less_rewarding_agent_ingroup_y, color='teal'\n",
        "  )\n",
        "  plt.fill_between(\n",
        "      freeze_levels,\n",
        "      avoidance_of_less_rewarding_agent_ingroup_y\n",
        "      - avoidance_of_less_rewarding_agent_ingroup_error,\n",
        "      avoidance_of_less_rewarding_agent_ingroup_y\n",
        "      + avoidance_of_less_rewarding_agent_ingroup_error,\n",
        "      alpha=0.2,\n",
        "      label='_nolegend_',\n",
        "      color='teal',\n",
        "  )\n",
        "  plt.plot(\n",
        "      freeze_levels,\n",
        "      avoidance_of_less_rewarding_agent_outgroup_y,\n",
        "      color='magenta',\n",
        "  )\n",
        "  plt.fill_between(\n",
        "      freeze_levels,\n",
        "      avoidance_of_less_rewarding_agent_outgroup_y\n",
        "      - avoidance_of_less_rewarding_agent_outgroup_error,\n",
        "      avoidance_of_less_rewarding_agent_outgroup_y\n",
        "      + avoidance_of_less_rewarding_agent_outgroup_error,\n",
        "      alpha=0.2,\n",
        "      label='_nolegend_',\n",
        "      color='magenta',\n",
        "  )\n",
        "  plt.legend(['In-group', 'Out-group'])\n",
        "  plt.xticks(freeze_levels, freeze_levels_str)\n",
        "  plt.xlabel('Freeze time')\n",
        "  plt.ylabel('Individuation')\n",
        "  plt.title(label)\n",
        "  plt.ylim(0, 1)\n",
        "  plt.savefig('discrimination.svg', dpi=200)\n",
        "\n",
        "  plt.figure(facecolor='white', figsize=size)\n",
        "  plt.bar(\n",
        "      range(number_of_runs),\n",
        "      avoidance_of_less_rewarding_agent_ingroup_y\n",
        "      - avoidance_of_less_rewarding_agent_outgroup_y,\n",
        "      color='k',\n",
        "  )\n",
        "  plt.xticks(range(number_of_runs), freeze_levels_str)\n",
        "  plt.xlabel('freeze time')\n",
        "  plt.ylim(0, 0.4)\n",
        "  plt.ylabel('Difference in individuation')\n",
        "\n",
        "  individuation_difference = np.array(\n",
        "      avoidance_of_less_rewarding_agent_ingroup_y\n",
        "      - avoidance_of_less_rewarding_agent_outgroup_y\n",
        "  )\n",
        "  plt.savefig('discrimination_difference.svg', dpi=200)\n",
        "\n",
        "  plt.figure(facecolor='white', figsize=size)\n",
        "  group_bias = np.array([np.mean(data) for data in bias])\n",
        "  grey_values = np.linspace(0.2, 1, num=number_of_runs)\n",
        "  for i in range(number_of_runs):\n",
        "    plt.scatter(\n",
        "        individuation_difference[i],\n",
        "        group_bias[i],\n",
        "        marker='.',\n",
        "        c='black',\n",
        "        s=500,\n",
        "        alpha=grey_values[i],\n",
        "    )\n",
        "\n",
        "  plt.ylabel('In group bias')\n",
        "  plt.xlabel('Difference in individuation hard pixel')\n",
        "  plt.xlim(0, 0.35)\n",
        "  plt.ylim(0.2, 0.35)\n",
        "  plt.xticks([0, 0.1, 0.2, 0.3])\n",
        "  plt.yticks([0.2, 0.25, 0.3, 0.35])\n",
        "\n",
        "  correlation = scipy.stats.pearsonr(group_bias, individuation_difference)\n",
        "  print(\n",
        "      'Group bias and discrimination difference: r',\n",
        "      np.round(correlation[0], decimals=2),\n",
        "      'p=',\n",
        "      np.round(correlation[1], decimals=3),\n",
        "  )\n",
        "  b, a = np.polyfit(individuation_difference, group_bias, deg=1)\n",
        "  xseq = np.linspace(\n",
        "      min(individuation_difference), max(individuation_difference), num=100\n",
        "  )\n",
        "  # Plot regression line\n",
        "  plt.plot(xseq, a + b * xseq, color='grey', lw=2.5)\n",
        "  plt.savefig('discrimination_bias_correlation.svg', dpi=200)\n",
        "  return individuation_difference, group_bias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xoukqeAqbYhr"
      },
      "outputs": [],
      "source": [
        "#@title Smoothing function\n",
        "def smooth(data: np.ndarray, *, smooth_size: int) -\u003e np.ndarray:\n",
        "  \"\"\"A common smoothing function.\n",
        "\n",
        "  Args:\n",
        "    data: Array to be smoothed.\n",
        "    smooth_size: How much to smooth the data.\n",
        "\n",
        "  Returns:\n",
        "    Smoothed array.\n",
        "  \"\"\"\n",
        "  if smooth_size == -1:\n",
        "    out = data\n",
        "  else:\n",
        "    alpha = 2 / (smooth_size + 1.0)\n",
        "    alpha_rev = 1 - alpha\n",
        "    n = data.shape[0]\n",
        "\n",
        "    pows = alpha_rev ** (np.arange(n + 1))\n",
        "\n",
        "    scale_arr = 1 / pows[:-1]\n",
        "    offset = data[0] * pows[1:]\n",
        "    pw0 = alpha * alpha_rev ** (n - 1)\n",
        "\n",
        "    mult = data * pw0 * scale_arr\n",
        "    cumsums = mult.cumsum()\n",
        "    out = offset + cumsums * scale_arr[::-1]\n",
        "  return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5JTysjc7CPdq"
      },
      "source": [
        "Figure 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n_VgGlmOrYTx"
      },
      "outputs": [],
      "source": [
        "df_list = load_dataframes(\n",
        "    file_label='fig1', number_of_files=5, downsample=DOWNSAMPLE\n",
        ")\n",
        "x, y_differences, y_errors, _, _ = plot_metric_style(\n",
        "    dataframes=df_list,\n",
        "    eval_name='two_colors',\n",
        "    first_choice='red',\n",
        "    second_choice='blue',\n",
        "    number_of_timebins=NUMBER_OF_TIMEBINS,\n",
        "    number_of_agents_to_eval=6,\n",
        "    titles=LEGEND,\n",
        ")\n",
        "bias_sums_fig1 = overview_plot(\n",
        "    x=x,\n",
        "    y_differences=y_differences,\n",
        "    y_errors=y_errors,\n",
        "    legend_strings=LEGEND,\n",
        "    ylims=YLIM,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDUmpa24LU9c"
      },
      "source": [
        "Fig 2 A \u0026 5 A"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XR_c8UFnNOIa"
      },
      "outputs": [],
      "source": [
        "df_list_correlated_colors = load_dataframes(\n",
        "    file_label='fig2_correlated_colors',\n",
        "    number_of_files=5,\n",
        "    downsample=DOWNSAMPLE\n",
        "    )\n",
        "x, ydiffs_correlated_colors, y_errors_correlated_colors, _, _ = (\n",
        "    plot_metric_style(\n",
        "        dataframes=df_list_correlated_colors,\n",
        "        eval_name='two_colors',\n",
        "        first_choice='red',\n",
        "        second_choice='blue',\n",
        "        number_of_timebins=NUMBER_OF_TIMEBINS,\n",
        "        number_of_agents_to_eval=6,\n",
        "        titles=LEGEND\n",
        "        )\n",
        ")\n",
        "bias_sums_close = overview_plot(\n",
        "    x=x,\n",
        "    y_differences=ydiffs_correlated_colors,\n",
        "    y_errors=y_errors_correlated_colors,\n",
        "    legend_strings=LEGEND,\n",
        "    ylims=YLIM\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zBvjDMvdNIJO"
      },
      "outputs": [],
      "source": [
        "df_list_very_correlated_colors = load_dataframes(\n",
        "    file_label='fig2_very_correlated_colors',\n",
        "    number_of_files=5,\n",
        "    downsample=DOWNSAMPLE,\n",
        ")\n",
        "x, ydiffs_list_very_correlated_colors, y_errors_very_correlated_colors, _, _ = (\n",
        "    plot_metric_style(\n",
        "        dataframes=df_list_very_correlated_colors,\n",
        "        eval_name='two_colors',\n",
        "        first_choice='red',\n",
        "        second_choice='blue',\n",
        "        number_of_timebins=NUMBER_OF_TIMEBINS,\n",
        "        number_of_agents_to_eval=6,\n",
        "        titles=LEGEND,\n",
        "    )\n",
        ")\n",
        "bias_sums_very_close = overview_plot(\n",
        "    x=x,\n",
        "    y_differences=ydiffs_list_very_correlated_colors,\n",
        "    y_errors=y_errors_very_correlated_colors,\n",
        "    legend_strings=LEGEND,\n",
        "    ylims=YLIM,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t-60jNZxNEmf"
      },
      "outputs": [],
      "source": [
        "\n",
        "df_list_one_resource = load_dataframes(\n",
        "    file_label='fig5_one_resource', number_of_files=5, downsample=DOWNSAMPLE\n",
        ")\n",
        "x, ydiffs_one_color, y_errors_one_resource, _, _ = plot_metric_style(\n",
        "    dataframes=df_list_one_resource,\n",
        "    eval_name='two_colors',\n",
        "    first_choice='red',\n",
        "    second_choice='blue',\n",
        "    number_of_timebins=NUMBER_OF_TIMEBINS,\n",
        "    number_of_agents_to_eval=6,\n",
        "    titles=LEGEND,\n",
        ")\n",
        "bias_sums_one_color = overview_plot(\n",
        "    x=x,\n",
        "    y_differences=ydiffs_one_color,\n",
        "    y_errors=y_errors_one_resource,\n",
        "    legend_strings=LEGEND,\n",
        "    ylims=YLIM,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b8CQli6oHmOp"
      },
      "outputs": [],
      "source": [
        "setting_colors = [\n",
        "    '#6b6b73',\n",
        "    '#f58231',\n",
        "    '#dcbeff',\n",
        "    '#800000',\n",
        "    '#ffe119',\n",
        "    '#000075',\n",
        "    '#a9a9a9',\n",
        "    '#000000',\n",
        "]\n",
        "plt.subplots(1, 1, facecolor='white', figsize=(4, 4))\n",
        "\n",
        "biases = np.stack((bias_sums_one_color, bias_sums_fig1[:5]))\n",
        "\n",
        "plt.subplot(1, 1, 1)\n",
        "for i in range(5):\n",
        "  plt.plot(biases[:, i], 'o-', c=setting_colors[i])\n",
        "plt.legend(\n",
        "    ['8:0|8:0', '8:0|7:1', '8:0|6:2', '8:0|5:3', '8:0|4:4'],\n",
        "    bbox_to_anchor=(0.85, 0.75),\n",
        ")\n",
        "\n",
        "plt.xticks([0, 1], ['one color', 'three colors'])\n",
        "plt.xlabel('Number of resources')\n",
        "plt.ylabel('In group bias')\n",
        "plt.ylim(-0, 1)\n",
        "plt.xlim(-0.2, 1.2)\n",
        "\n",
        "plt.savefig('one_color.svg', dpi=200)\n",
        "\n",
        "biases = np.stack((bias_sums_fig1[:5], bias_sums_close, bias_sums_very_close))\n",
        "plt.subplots(1, 1, facecolor='white', figsize=(4, 4))\n",
        "plt.subplot(1, 1, 1)\n",
        "for i in range(5):\n",
        "  plt.plot(biases[:, i], 'o-', c=setting_colors[i])\n",
        "plt.xticks([0, 1, 2], ['300', '200', '100'])\n",
        "plt.xlabel('RGB distance')\n",
        "plt.ylim(0, 1)\n",
        "plt.xlim(-0.3, 2.3)\n",
        "plt.ylabel('In group bias')\n",
        "\n",
        "plt.savefig('similar_colors.svg', dpi=200)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aPw5MNWyLK_a"
      },
      "outputs": [],
      "source": [
        "df_list_walled = load_dataframes(\n",
        "    file_label='fig2_walled', number_of_files=5, downsample=DOWNSAMPLE\n",
        ")\n",
        "x, ydiffs_walled, y_errors_walled, _, _ = plot_metric_style(\n",
        "    dataframes=df_list_walled,\n",
        "    eval_name='two_colors',\n",
        "    first_choice='red',\n",
        "    second_choice='blue',\n",
        "    number_of_timebins=NUMBER_OF_TIMEBINS,\n",
        "    number_of_agents_to_eval=6,\n",
        "    titles=LEGEND,\n",
        ")\n",
        "bias_sums_walled = overview_plot(\n",
        "    x=x,\n",
        "    y_differences=ydiffs_walled,\n",
        "    y_errors=y_errors_walled,\n",
        "    legend_strings=LEGEND,\n",
        "    ylims=YLIM,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iq-xr2mXomoh"
      },
      "outputs": [],
      "source": [
        "\n",
        "df_list_celled = load_dataframes(\n",
        "    file_label='fig2_celled', number_of_files=5, downsample=DOWNSAMPLE\n",
        ")\n",
        "x, ydiffs_celled, y_errors_celled, _, _ = plot_metric_style(\n",
        "    dataframes=df_list_celled,\n",
        "    eval_name='two_colors',\n",
        "    first_choice='red',\n",
        "    second_choice='blue',\n",
        "    number_of_timebins=NUMBER_OF_TIMEBINS,\n",
        "    number_of_agents_to_eval=6,\n",
        "    titles=LEGEND,\n",
        ")\n",
        "bias_sums_celled = overview_plot(\n",
        "    x=x,\n",
        "    y_differences=ydiffs_celled,\n",
        "    y_errors=y_errors_celled,\n",
        "    legend_strings=LEGEND,\n",
        "    ylims=YLIM,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LM19qqzOxzW3"
      },
      "source": [
        "Figure 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3X_Jobtvx1B_"
      },
      "outputs": [],
      "source": [
        "\n",
        "freeze_levels = [16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64]\n",
        "\n",
        "df_list_individuation = load_dataframes(\n",
        "    file_label='fig4_brighter_pixel', number_of_files=13, downsample=DOWNSAMPLE\n",
        ")\n",
        "\n",
        "_, ydiffs_individuation, _, _, _ = plot_metric_style(\n",
        "    dataframes=df_list_individuation,\n",
        "    eval_name='two_colors',\n",
        "    first_choice='red',\n",
        "    second_choice='blue',\n",
        "    number_of_timebins=NUMBER_OF_TIMEBINS,\n",
        "    number_of_agents_to_eval=4,\n",
        "    titles=freeze_levels,\n",
        ")\n",
        "_, _, _, discplot_individuation_red, _ = plot_metric_style(\n",
        "    dataframes=df_list_individuation,\n",
        "    eval_name='red_bad_v_red_new',\n",
        "    first_choice='red_bad',\n",
        "    second_choice='red_new',\n",
        "    number_of_timebins=NUMBER_OF_TIMEBINS,\n",
        "    number_of_agents_to_eval=4,\n",
        "    titles=freeze_levels,\n",
        ")\n",
        "_, _, _, discplot_individuation_blue, _ = plot_metric_style(\n",
        "    dataframes=df_list_individuation,\n",
        "    eval_name='blue_bad_v_blue_new',\n",
        "    first_choice='blue_bad',\n",
        "    second_choice='blue_new',\n",
        "    number_of_timebins=NUMBER_OF_TIMEBINS,\n",
        "    number_of_agents_to_eval=4,\n",
        "    titles=freeze_levels,\n",
        ")\n",
        "\n",
        "individuation_difference_easy, group_bias_easy = individuation_analyses(\n",
        "    freeze_levels=freeze_levels,\n",
        "    red_individuation=discplot_individuation_red,\n",
        "    blue_individuation=discplot_individuation_blue,\n",
        "    bias=ydiffs_individuation,\n",
        "    label='Brighter pixel (easier individuation)',\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8uwDaYeaxy24"
      },
      "outputs": [],
      "source": [
        "df_list_individuation_duller = load_dataframes(\n",
        "    file_label='fig4_duller_pixel', number_of_files=13, downsample=DOWNSAMPLE\n",
        ")\n",
        "\n",
        "_, ydiffs_individuation_duller, _, _, _ = plot_metric_style(\n",
        "    dataframes=df_list_individuation_duller,\n",
        "    eval_name='two_colors',\n",
        "    first_choice='red',\n",
        "    second_choice='blue',\n",
        "    number_of_timebins=NUMBER_OF_TIMEBINS,\n",
        "    number_of_agents_to_eval=4,\n",
        "    titles=freeze_levels,\n",
        ")\n",
        "_, _, _, discplot_individuation_duller_red, _ = plot_metric_style(\n",
        "    dataframes=df_list_individuation_duller,\n",
        "    eval_name='red_bad_v_red_new',\n",
        "    first_choice='red_bad',\n",
        "    second_choice='red_new',\n",
        "    number_of_timebins=NUMBER_OF_TIMEBINS,\n",
        "    number_of_agents_to_eval=4,\n",
        "    titles=freeze_levels,\n",
        ")\n",
        "_, _, _, discplot_individuation_duller_blue, _ = plot_metric_style(\n",
        "    dataframes=df_list_individuation_duller,\n",
        "    eval_name='blue_bad_v_blue_new',\n",
        "    first_choice='blue_bad',\n",
        "    second_choice='blue_new',\n",
        "    number_of_timebins=NUMBER_OF_TIMEBINS,\n",
        "    number_of_agents_to_eval=4,\n",
        "    titles=freeze_levels,\n",
        ")\n",
        "\n",
        "individuation_difference_middle, group_bias_middle = individuation_analyses(\n",
        "    freeze_levels=freeze_levels,\n",
        "    red_individuation=discplot_individuation_duller_red,\n",
        "    blue_individuation=discplot_individuation_duller_blue,\n",
        "    bias=ydiffs_individuation_duller,\n",
        "    label='Duller pixel (harder individuation)',\n",
        ")\n"
      ]
    },
    {
      "metadata": {
        "id": "RgTqBcCmYa7B"
      },
      "cell_type": "markdown",
      "source": [
        "Copyright 2024 DeepMind Technologies Limited.\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "you may not use this file except in compliance with the License.\n",
        "You may obtain a copy of the License at\n",
        "\n",
        "    https://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software\n",
        "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "See the License for the specific language governing permissions and\n",
        "limitations under the License."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [
        {
          "file_id": "1Gw-b0QIqeHYos1CiVp0IKVV661qCeVz0",
          "timestamp": 1716516566078
        }
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
